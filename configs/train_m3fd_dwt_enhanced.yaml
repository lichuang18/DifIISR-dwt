# DifIISR-DWT 增强版配置 - 添加边缘损失和频率损失
#
# 改进策略：
#   1. LPIPS: 放宽时间步权重（t>=10从0.001改为0.1）
#   2. 边缘损失: Sobel算子，增强边缘锐度
#   3. 频率损失: FFT高频损失，增强高频细节
#
# 损失函数：
#   Total Loss = MSE + λ_lpips * LPIPS + λ_edge * Edge + λ_freq * Freq

exp_name: DifIISR_DWT_Enhanced

model:
  target: models.unet.UNetModelSwin
  ckpt_path: ~
  params:
    image_size: 64
    in_channels: 42     # 21(噪声子带) + 21(LQ条件)
    model_channels: 160
    out_channels: 21    # 输出全部子带 (level2: 12 + level1: 9)
    cond_lq: True
    attention_resolutions: [64,32,16,8]
    dropout: 0
    channel_mult: [1, 2, 2, 4]
    num_res_blocks: [2, 2, 2, 2]
    conv_resample: True
    dims: 2
    use_fp16: False
    num_head_channels: 32
    use_scale_shift_norm: True
    resblock_updown: False
    swin_depth: 2
    swin_embed_dim: 192
    window_size: 8
    mlp_ratio: 4

diffusion:
  target: models.script_util.create_gaussian_diffusion_test
  params:
    sf: 4
    schedule_name: exponential
    schedule_kwargs:
      power: 0.3
    etas_end: 0.99
    steps: 15
    min_noise_level: 0.04
    kappa: 2.0
    weighted_mse: False
    predict_type: xstart
    timestep_respacing: ~
    scale_factor: 1.0
    normalize_input: True
    latent_flag: True

autoencoder:
  target: ldm.models.dwt_autoencoder.DWTModelAllBandsLearnableTorch
  ckpt_path: ~
  use_fp16: False
  params:
    wavelet: haar
    level: 2

# 增强版感知损失配置
#
# 简化策略：先只用LPIPS + 边缘损失，不加频率损失
# 避免多损失难以收敛的问题
#
# 权重设计（修正版）：
#   - MSE: 1.0 (基础，主导训练)
#   - LPIPS: 0.02 → 0.1 (渐进，辅助)
#   - Edge: 0.1 (固定，与LPIPS贡献相当)
#
# 预期贡献比例：
#   MSE: 0.007 (50%, 主导)
#   LPIPS: 0.02 * 0.2 = 0.004 (28%)
#   Edge: 0.1 * 0.5 * 0.06 = 0.003 (22%)
perceptual_loss:
  enabled: True
  lpips_weight_start: 0.02   # 降低起始权重
  lpips_weight_end: 0.1      # 降低结束权重
  lpips_net: 'vgg'

  # 边缘损失 - Sobel算子
  edge_loss_enabled: True
  edge_loss_weight: 0.1      # 提高到0.1，与LPIPS贡献相当

  # 频率损失 - 先关闭，避免多损失难收敛
  freq_loss_enabled: False
  freq_loss_weight: 0.05

# Real-ESRGAN风格退化配置
degradation:
  sf: 4

  # 第一阶段退化
  blur_kernel_size: 21
  kernel_list: ['iso', 'aniso', 'generalized_iso', 'generalized_aniso', 'plateau_iso', 'plateau_aniso']
  kernel_prob: [0.45, 0.25, 0.12, 0.03, 0.12, 0.03]
  blur_sigma: [0.2, 3.0]
  betag_range: [0.5, 4.0]
  betap_range: [1, 2.0]

  resize_prob: [0.2, 0.7, 0.1]
  resize_range: [0.15, 1.5]

  gaussian_noise_prob: 0.5
  noise_range: [1, 30]
  poisson_scale_range: [0.05, 3.0]
  gray_noise_prob: 0.4

  jpeg_range: [30, 95]

  # 第二阶段退化
  second_order_prob: 0.5
  second_blur_prob: 0.8

  blur_kernel_size2: 15
  kernel_list2: ['iso', 'aniso', 'generalized_iso', 'generalized_aniso', 'plateau_iso', 'plateau_aniso']
  kernel_prob2: [0.45, 0.25, 0.12, 0.03, 0.12, 0.03]
  blur_sigma2: [0.2, 1.5]
  betag_range2: [0.5, 4.0]
  betap_range2: [1, 2.0]

  resize_prob2: [0.3, 0.4, 0.3]
  resize_range2: [0.3, 1.2]

  gaussian_noise_prob2: 0.5
  noise_range2: [1, 25]
  poisson_scale_range2: [0.05, 2.5]
  gray_noise_prob2: 0.4

  jpeg_range2: [30, 95]

data:
  type: degradation
  train:
    hr_dir: /home/lch/sr_recons/dataset/M3FD_processed/train/HR
    gt_size: 256
    scale: 4
    use_hflip: True
    use_rot: True
    length: ~
  val:
    hr_dir: /home/lch/sr_recons/dataset/M3FD_processed/val/HR
    length: 20

train:
  output_dir: /home/lch/sr_recons/experiments
  batch_size: 8
  val_batch_size: 4
  lr: 5e-5
  weight_decay: 0.01
  iterations: 50000
  min_lr: 1e-6

  use_ema: True
  ema_rate: 0.999
  use_scheduler: True

  log_freq: 100
  val_freq: 1000
  save_freq: 2000

  num_workers: 4
