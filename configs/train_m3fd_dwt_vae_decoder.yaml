# DifIISR 最终方案：DWT编码 + UNet融合 + VAE解码
#
# 核心思路：
#   - 编码：DWT (0参数，高效)
#   - UNet：输入42通道(21+21)，输出21通道（在DWT空间扩散）
#   - 解码：投影层(21→3) + 原版预训练VAE Decoder（有生成能力）
#
# 数据流：
#   LR → DWT.encode → 64×64×21 → UNet(in=42,out=21) → 64×64×21 → Proj(21→3) → VAE.decode → SR
#
# 收益：
#   - Encoder参数：24.5M → 0 (-100%)
#   - 编码计算量：57M MACs → 1M MACs (-98%)
#   - 保留VAE Decoder的生成能力

exp_name: DifIISR_DWT_VAE_Decoder

model:
  target: models.unet.UNetModelSwin
  ckpt_path: ~
  params:
    image_size: 64
    in_channels: 42     # 21(噪声DWT子带) + 21(LQ DWT子带)
    model_channels: 160
    out_channels: 21    # 输出21通道，在DWT空间扩散
    cond_lq: True
    attention_resolutions: [64,32,16,8]
    dropout: 0
    channel_mult: [1, 2, 2, 4]
    num_res_blocks: [2, 2, 2, 2]
    conv_resample: True
    dims: 2
    use_fp16: False
    num_head_channels: 32
    use_scale_shift_norm: True
    resblock_updown: False
    swin_depth: 2
    swin_embed_dim: 192
    window_size: 8
    mlp_ratio: 4

diffusion:
  target: models.script_util.create_gaussian_diffusion_test
  params:
    sf: 4
    schedule_name: exponential
    schedule_kwargs:
      power: 0.3
    etas_end: 0.99
    steps: 15
    min_noise_level: 0.04
    kappa: 2.0
    weighted_mse: False
    predict_type: xstart
    timestep_respacing: ~
    scale_factor: 1.0
    normalize_input: True
    latent_flag: True

# DWT编码器（只负责编码，输出21通道）
dwt_encoder:
  target: ldm.models.dwt_autoencoder.DWTEncoderOnly
  params:
    wavelet: haar
    level: 2

# VAE解码器（使用原版预训练权重，只用decoder部分）
autoencoder:
  target: ldm.models.autoencoder.VQModelTorch
  ckpt_path: weights/autoencoder_vq_f4.pth
  use_fp16: False
  params:
    embed_dim: 3
    n_embed: 8192
    ddconfig:
      double_z: False
      z_channels: 3
      resolution: 256
      in_channels: 3
      out_ch: 3
      ch: 128
      ch_mult:
      - 1
      - 2
      - 4
      num_res_blocks: 2
      attn_resolutions: []
      dropout: 0.0
      padding_mode: zeros

# 感知损失配置
perceptual_loss:
  enabled: True
  lpips_weight_start: 0.05
  lpips_weight_end: 0.2
  lpips_net: 'vgg'

  edge_loss_enabled: True
  edge_loss_weight: 0.1

  freq_loss_enabled: False
  freq_loss_weight: 0.05

# Real-ESRGAN风格退化配置
degradation:
  sf: 4

  blur_kernel_size: 21
  kernel_list: ['iso', 'aniso', 'generalized_iso', 'generalized_aniso', 'plateau_iso', 'plateau_aniso']
  kernel_prob: [0.45, 0.25, 0.12, 0.03, 0.12, 0.03]
  blur_sigma: [0.2, 3.0]
  betag_range: [0.5, 4.0]
  betap_range: [1, 2.0]

  resize_prob: [0.2, 0.7, 0.1]
  resize_range: [0.15, 1.5]

  gaussian_noise_prob: 0.5
  noise_range: [1, 30]
  poisson_scale_range: [0.05, 3.0]
  gray_noise_prob: 0.4

  jpeg_range: [30, 95]

  second_order_prob: 0.5
  second_blur_prob: 0.8

  blur_kernel_size2: 15
  kernel_list2: ['iso', 'aniso', 'generalized_iso', 'generalized_aniso', 'plateau_iso', 'plateau_aniso']
  kernel_prob2: [0.45, 0.25, 0.12, 0.03, 0.12, 0.03]
  blur_sigma2: [0.2, 1.5]
  betag_range2: [0.5, 4.0]
  betap_range2: [1, 2.0]

  resize_prob2: [0.3, 0.4, 0.3]
  resize_range2: [0.3, 1.2]

  gaussian_noise_prob2: 0.5
  noise_range2: [1, 25]
  poisson_scale_range2: [0.05, 2.5]
  gray_noise_prob2: 0.4

  jpeg_range2: [30, 95]

data:
  type: degradation
  train:
    hr_dir: /home/lch/sr_recons/dataset/M3FD_processed/train/HR
    gt_size: 256
    scale: 4
    use_hflip: True
    use_rot: True
    length: ~
  val:
    hr_dir: /home/lch/sr_recons/dataset/M3FD_processed/val/HR
    length: 20

train:
  output_dir: /home/lch/sr_recons/experiments
  batch_size: 4
  val_batch_size: 4
  lr: 5e-5
  weight_decay: 0.01
  iterations: 8000
  min_lr: 1e-6

  use_ema: True
  ema_rate: 0.999
  use_scheduler: True

  log_freq: 100
  val_freq: 500
  save_freq: 2000

  num_workers: 4
